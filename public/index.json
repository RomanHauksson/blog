[{"content":"context In 2021 March, i had to write a paper called the \u0026ldquo;Extended Essay\u0026rdquo;, which was sort of the culminating work for the International Baccalaureate program at my high school. I was one of the 3.2% of candidates to write it under the \u0026ldquo;Mathematics\u0026rdquo; subject and one of 20% to earn an A for it!1 :D\nEven though it\u0026rsquo;s poorly written, i decided to throw it up here, with some of the cruft trimmed off. The conclusion is that tangent lines to circles can be modeled by the following system of equations.\n$$ \\begin{aligned} a \u0026amp;= x_1-x_2 \u0026amp; b \u0026amp;= y_1-y_2 \u0026amp; c \u0026amp;= r_1 \\pm r_2 \\end{aligned} $$\n$$\\begin{aligned} S_t = \\frac{b \\sqrt{a^2+b^2-c^2} \\pm ac}{a \\sqrt{a^2+b^2-c^2} \\mp bc} \\end{aligned}$$\n$$\\begin{aligned} x_i \u0026amp;= x_1 \\mp \\frac{S_t r_1}{\\sqrt{S_t^2+1}} \u0026amp; y_i \u0026amp;= \\pm \\sqrt{r_1^2-(x_i-x_1)^2}+y_1 \\end{aligned}$$\n$$\\begin{aligned} y \u0026amp;= S_t(x - x_i) + y_i \\end{aligned}$$\nSubstitute $(x_1, y_1)$ with the coordinates of the first circle and $r_1$ with its radius. Likewise, substitute $x_2$, $y_2$, and $r_2$ for the second circle.\nUse different states of the three plus–minus signs to generate eight different possible lines, and manually choose four from those eight as your four tangent lines (two internal and two external).\nintroduction A couple years ago, i sometimes liked to make art in Desmos (an online graphing calculator), and one of my almost-finished pieces was a bicycle. I had written the equation for each line that made up the drawing of the bike, and i could even adjust the seat height and pedal lengths with variable sliders.\nHowever, one feature of the bike was notably missing: the chain connecting the gears. This would have taken the form of lines tangent to the two circles representing the gears, but i didn\u0026rsquo;t know how to graph that precisely at the time.\n① a bicycle chain, resembling circles with tangent lines I\u0026rsquo;ve since lost the original Desmos project, but my unsolved problem has tormented me ever since. How do you write the linear equation for each of the lines that are tangent to two circles if you know the radii and coordinates of those circles?\nexternal tangent lines There are two circles:\nCircle 1 with center $C_1=(x_1,y_1)$ and radius $r_1$ Circle 2 with center $C_2=(x_2,y_2)$ and radius $r_2$ $r_1\\geq r_2$ ② external tangents of two circles A line is drawn between the centers of the circles, called $C(x)$, and both external tangent lines $t_1(x)$ and $t_2(x)$ are drawn. The points of intersection between the tangent lines and circle 1 are $i_1=(x_{i1},y_{i1})$ and $i_2=(x_{i2},y_{i2})$. The points of intersection on circle 2 are $i_3=(x_{i3},y_{i3})$ and $i_4=(x_{i4},y_{i4})$. All three lines intersect at point $P$. The angle between the first tangent line and the line that connects the centers of the circles is $\\angle C_1Pi_1$.\nslopes of the external tangents Angle $\\angle C_1 i_1 P$ is a right angle because it is the angle between a tangent to a circle and a radius that passes through the point of tangency, and the same is true for $\\angle C_2 i_3 P$⁠. Because these right angles are congruent, and because $\\triangle C_1 P i_1$ and $\\triangle C_2 P i_2$ share the angle $\\angle C_1 P i_1$, this makes the triangles similar.\nBecause these triangles are similar, the ratio between corresponding sides is constant. Therefore,\n$$\\frac{r_1}{r_2} = \\frac{h_1}{h_2}$$\nWe can substitute $h_1$ with the two lengths that make it up: $h_2+d$. Then, by rewriting the equation, we can solve for $h_2$.\n$$ \\begin{aligned} \\frac{r_1}{r_2} \u0026amp;= \\frac{h_2+d}{h_2} \\\\ r_1h_2 \u0026amp;= r_2(h_2+d) \\\\ r_1h_2 \u0026amp;= r_2h_2+r_2d \\\\ r_1h_2 \u0026amp;= r_2h_2+r_2d \\\\ r_1h_2-r_2h_2 \u0026amp;= r_2d \\\\ h_2(r_1-r_2) \u0026amp;= r_2d \\\\ h_2 \u0026amp;= \\frac{r_2d}{r_1-r_2} \\end{aligned} $$\nNow that $h_2$ is defined, we can use trigonometry to define the angle between the line that connects the circles\u0026rsquo; centers and the first tangent line. This angle is $\\angle C_2 P i_3$, or $\\theta$.\nConsider triangle $\\triangle C_2 i_3 P$:\n③ triangle △C2i3P Because of the definition of the sine of an angle (the ratio between the opposing side and the hypotenuse in a right triangle), $\\sin{\\theta} =\\frac{r_2}{h_2}$. By taking the inverse sine of each side, we can define $\\theta$: $$\\theta =\\arcsin{\\left(\\frac{r_2}{h_2}\\right)}$$ To find the angle of the first external tangent line, we can add $\\theta$ to the angle of $C(x)$ with respect to the $x$-axis. Similarly, we can subtract $\\theta$ from the angle of $C(x)$ to find the angle of the second tangent line. $$\\begin{aligned} \\theta_t=\\theta_C \\pm \\theta \\end{aligned}$$\n④ angles of external tangents and C(x) But how do we know the angle of $C(x)$? The slope of $C(x)$ can be found by using the slope formula and substituting with the coordinates of the centers of the circles. Then, we can convert this slope into an angle by finding its inverse tangent.\n$$\\begin{aligned} \\theta_C \u0026amp;= \\arctan{\\left( S_C \\right)} \\\\ \\theta_C \u0026amp;= \\arctan{\\left( \\frac{\\Delta y}{\\Delta x} \\right)} \\\\ \\theta_C \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\end{aligned} $$\nNow, we can substitute the values of $\\theta_C$ and $\\theta$: $$ \\begin{aligned} \\theta_t \u0026amp;= \\theta_C \\pm \\theta \\\\ \\theta_C \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\\\ \\theta \u0026amp;= \\arcsin{\\left( \\frac{r_2}{h_2} \\right)} \\\\ \\theta_t \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\pm \\arcsin{\\left( \\frac{r_2}{h_2} \\right)} \\end{aligned} $$\nThen, we can substitute for $h_2$ and simplify:\n$$ \\begin{aligned} h_2 \u0026amp;= \\frac{r_2d}{r_1-r_2} \\\\ \\theta_t \u0026amp;= \\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_2}{\\frac{r_2d}{r_1 - r_2}}\\right)} \\\\ \\theta_t \u0026amp;= \\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_2(r_1 - r_2)}{r_2d}\\right)} \\\\ \\theta_t \u0026amp;= \\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 - r_2}{d}\\right)} \\end{aligned} $$\nWe can then substitute for $d$. $d$ is the distance between the centers of the circles, so we can use the distance formula with $C_1$ and $C_2$ as points.\n$$ \\begin{aligned} d \u0026amp;= \\sqrt{(x_1-x_2)^2+(y_1-y_2)^2} \\\\ \\theta_t \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\pm \\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)} \\end{aligned} $$\nBecause the tangent of the angle of a line produces its slope, we can take the tangent of both sides to generate an equation for both of the slopes of the external tangent lines: $$S_t = \\tan{\\left(\\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)}$$ This equation, which uses trigonometric functions inside of a trigonometric function, is not very elegant. To rewrite it, we can use a trigonometric identity for the tangent of a sum or difference:\n$$\\tan{(\\alpha \\pm \\beta)}=\\frac{\\tan{(\\alpha)} \\pm \\tan{(\\beta)}}{1 \\mp \\tan{(\\alpha)}\\tan{(\\beta)}}$$\nIn this case, $\\alpha = \\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)}$ and $\\beta = \\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}$.\nFor ease of explanation, we\u0026rsquo;ll first find $\\tan{(\\alpha)}$ and $\\tan{(\\beta)}$ separately, then substitute them into the identity.\nThe tangent of $\\alpha$ is simple to find, because the arctangent and the tangent functions cancel each other out:\n$$\\begin{aligned} \\tan{(\\alpha)} \u0026amp;= \\tan{\\left( \\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\right)} \\\\ \\tan{(\\alpha)} \u0026amp;= \\frac{y_1-y_2}{x_1-x_2} \\end{aligned}$$\nHowever, the tangent of $\\beta$ is trickier because the tangent function doesn\u0026rsquo;t cancel out the arcsine function. To remedy this, we can use an identity for the tangent of an arcsine, as demonstrated by figure 5.\n⑤ right triangle demonstration of tan (arcsin(x)) In figure 5, the sine of angle $\\theta$ is the ratio between the lengths of the opposite side and the hypotenuse, or $\\frac{x}{1}=x$. Therefore, the arcsine of this ratio equals $\\theta$: $$\\arcsin{(x)}=\\theta$$ The tangent of $\\theta$, or in other words, the tangent of $\\arcsin{(x)}$, is equal to the ratio between the opposite side and the adjacent side. The length of the adjacent side can be found using the Pythagorean theorem: $\\sqrt{1-x^2}$. Therefore, $$\\tan{\\left(\\arcsin{(x)}\\right)}=\\frac{x}{\\sqrt{1-x^2}}$$ We can now use this identity to find $\\tan{(\\beta)}$: $$ \\begin{aligned} \\tan{(\\beta)} \u0026amp;= \\tan{\\left(\\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}}{\\sqrt{1-\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)^2}} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}}{\\sqrt{1-\\frac{(r_1 - r_2)^2}{(x_1-x_2)^2+(y_1-y_2)^2}}} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}}{\\sqrt{\\frac{(x_1-x_2)^2+(y_1-y_2)^2}{(x_1-x_2)^2+(y_1-y_2)^2}-\\frac{(r_1 - r_2)^2}{(x_1-x_2)^2+(y_1-y_2)^2}}} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}}{\\sqrt{\\frac{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}{(x_1-x_2)^2+(y_1-y_2)^2}}} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}}{\\frac{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}} \\\\ \\tan{(\\beta)} \u0026amp;= \\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}} \\end{aligned} $$ Now that we know $\\tan{(\\alpha)}$ and $\\tan{(\\beta)}$, we can return to rewriting the slope equation using the identity for the tangent of a sum or difference.\n$$ \\begin{aligned} S_t \u0026amp;= \\tan{\\left(\\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)} \\\\ \\tan{(\\alpha \\pm \\beta)} \u0026amp;= \\frac{\\tan{(\\alpha)} \\pm \\tan{(\\beta)}}{1 \\mp \\tan{(\\alpha)}\\tan{(\\beta)}} \\\\ S_t \u0026amp;= \\frac{\\frac{y_1-y_2}{x_1-x_2} \\pm \\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}}{1 \\mp \\frac{y_1-y_2}{x_1-x_2} \\cdot \\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}} \\\\ S_t \u0026amp;= \\frac{\\frac{y_1-y_2}{x_1-x_2} \\pm \\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}}{1 \\mp \\frac{(y_1-y_2)(r_1 - r_2)}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}} \\end{aligned} $$\nWe can rewrite each term with a common denominator. $$\\begin{aligned} S_t \u0026amp;= \\frac{\\frac{(y_1-y_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}} \\pm \\frac{(x_1-x_2)(r_1 - r_2)}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}}{\\frac{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}} \\mp \\frac{(y_1-y_2)(r_1 - r_2)}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2}}} \\end{aligned}$$ Finally, multiplying each side by the common denominator yields the final equation for the slopes of the external tangent lines: $$S_t = \\frac{(y_1-y_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2} \\pm (x_1-x_2)(r_1 - r_2)}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2} \\mp (y_1-y_2)(r_1 - r_2)}$$ At first glance, this equation doesn\u0026rsquo;t appear any simpler than the one involving nested trigonometric functions. However, by applying the following substitutions, the symmetry and elegance of this equation becomes clear: $$\\begin{gathered} a = x_1-x_2 \\qquad b = y_1-y_2 \\qquad c = r_1-r_2 \\\\ S_t = \\frac{b \\sqrt{a^2+b^2-c^2} \\pm ac}{a \\sqrt{a^2+b^2-c^2} \\mp bc} \\end{gathered}$$\npoints on the external tangents In order to define an exact equation for the external tangents, defining the slopes isn\u0026rsquo;t enough. We also need a point on each of the slopes, and the easiest points to use are the points of tangency on circle 1.\nA point of tangency on circle 1 will have an instantaneous slope equal to that of the tangent line it corresponds to. Therefore, to figure out which points on circle 1 can qualify as points of tangency, we need to find the derivative (the slope at each point) of the equation of circle 1 and set it equal to the tangent\u0026rsquo;s slope, and then solve for the x-value of the point of tangency. This can then be fed back into the circle equation to define the other coordinate of the point of tangency, which would complete the definition of the tangent line function.\nThis method presents one key problem, however: a circle equation is not a function, and so its derivative would not be a function either. At each x-value in the domain of the graph of the circle, there are two possible y-values and two possible slopes, and as a result, there are two points on circle 1 that could qualify as points of tangency for each tangent line. Because there are two tangent lines, this makes four possible points of tangency, but only two of them are correct.\n⑥ two points of tangency on a circle that have the same instantaneous slope Ultimately, i decided to accept the fact that this approach would generate not two, but four possible external tangents, and someone using this equation would have to manually decide which definitions to use.\nThe first step is to find the derivative of the circle equation. However, this equation is not defined simply in terms of $y$, as it\u0026rsquo;s based on the Pythagorean theorem. $$(x-x_1)^2+(y-y_1)^2=r_1^2$$ Implicit differentiation would not work in this case, so we need to rewrite the circle equation in terms of $y$ before we differentiate it with respect to $x$. $$\\begin{aligned} (x-x_1)^2+(y-y_1)^2 \u0026amp;= r_1^2 \\\\ (y-y_1)^2 \u0026amp;= r_1^2-(x-x_1)^2 \\\\ y-y_1 \u0026amp;= \\pm \\sqrt{r_1^2-(x-x_1)^2} \\\\ y \u0026amp;= \\pm \\sqrt{r_1^2-(x-x_1)^2}+y_1 \\end{aligned}$$ Now, we can find the derivative of this equation to find the slope of any given point on circle 1.\n$$\\begin{aligned} \\frac{\\mathrm{d}}{\\mathrm{d}x} [y] \u0026amp;= \\frac{\\mathrm{d}}{\\mathrm{d}x} \\left[ \\pm \\sqrt{r_1^2-(x-x_1)^2}+y_1 \\right] \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{\\mathrm{d}}{\\mathrm{d}x} \\left[ \\sqrt{r_1^2-(x-x_1)^2} \\right] \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{\\mathrm{d}}{\\mathrm{d}x} \\left[ \\left( r_1^2-(x-x_1)^2 \\right)^{\\frac{1}{2}} \\right] \\end{aligned}$$\nWe can use the chain rule for derivatives to continue. $$\\begin{aligned} \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{1}{2} \\left( r_1^2-(x-x_1)^2 \\right)^{-\\frac{1}{2}} \\left( \\frac{\\mathrm{d}}{\\mathrm{d}x} \\left[ r_1^2-(x-x_1)^2 \\right] \\right) \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{1}{2 \\sqrt{r_1^2-(x-x_1)^2}} \\left( -\\frac{\\mathrm{d}}{\\mathrm{d}x} \\left[ (x-x_1)^2 \\right] \\right) \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{1}{2 \\sqrt{r_1^2-(x-x_1)^2}} \\left( 2(x-x_1)(1) \\right) \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{2(x-x_1)}{2 \\sqrt{r_1^2-(x-x_1)^2}} \\\\ \\frac{\\mathrm{d}y}{\\mathrm{d}x} \u0026amp;= \\pm \\frac{x-x_1}{\\sqrt{r_1^2-(x-x_1)^2}} \\end{aligned}$$ This resulting equation gives the relationship between the slope of the tangent line ($\\frac{\\mathrm{d}y}{\\mathrm{d}x}$) and the $x$-coordinate of the point of tangency on circle 1.\nWe need to rewrite this equation in terms of $x$, because in this case, $x$ is the $x$-coordinate of the point of tangency, which will be used in the tangent line equation. However, the algebra that enables us to do this is long and confusing. To help make the process easier to read, we will temporarily reassign each variable to a single letter each: $$\\begin{aligned} \\frac{\\mathrm{d}y}{\\mathrm{d}x} = S_t \u0026amp;= a \\\\ r_1 \u0026amp;= b \\\\ x = x_i \u0026amp;= c \\\\ x_1 \u0026amp;= d \\end{aligned}$$ Essentially, we can rewrite the equation as a sum of terms, which can be rearranged into a quadratic equation with multi-term coefficients. These can be plugged into the quadratic formula in order to solve for $c$, which represents $x_i$. $$\\begin{aligned} a \u0026amp;= \\pm \\frac{c-d}{\\sqrt{b^2-(c-d)^2}} \\\\ \\pm a \\sqrt{b^2-(c-d)^2} \u0026amp;= c-d \\\\ \\left( \\pm a \\sqrt{b^2-(c-d)^2} \\right)^2 \u0026amp;= (c-d)^2 \\\\ a^2(b^2-(c-d)^2) \u0026amp;= (c-d)^2 \\\\ a^2(b^2-(c^2-2cd+d^2)) \u0026amp;= c^2 - 2cd +d^2 \\\\ a^2(b^2-c^2+2cd-d^2) \u0026amp;= c^2 - 2cd +d^2 \\\\ a^2b^2-a^2c^2+2a^2cd-a^2d^2 \u0026amp;= c^2 - 2cd +d^2 \\\\ a^2b^2 - a^2c^2 + 2a^2cd - a^2d^2 - c^2 + 2cd - d^2 \u0026amp;= 0 \\\\ - a^2c^2 - c^2 + 2a^2cd + 2cd + a^2b^2 - a^2d^2 - d^2 \u0026amp;= 0 \\\\ c^2(- a^2 - 1) + c(2a^2d + 2d) + (a^2b^2 - a^2d^2 - d^2) \u0026amp;= 0 \\end{aligned}$$ Now that the equation is in the form of a quadratic, we can use the quadratic formula to determine the solutions for $c$. $$c = \\frac{-(2a^2d+2d) \\pm \\sqrt{(2a^2d+2d)^2-4(-a^2-1)(a^2b^2 - a^2d^2 - d^2)}}{2(-a^2-1)}$$ For readability, we\u0026rsquo;ll simplify the radicand in the quadratic formula separately: $$\\begin{gathered} (2a^2d+2d)^2-4(-a^2-1)(a^2b^2 - a^2d^2 - d^2) \\\\ 4a^4d^2 + 8a^2d^2 + 4d^2 - 4(-a^4b^2 + a^4d^2 +a^2d^2 -a^2b^2 +a^2d^2 +d^2) \\\\ 4a^4d^2 + 8a^2d^2 + 4d^2 + 4a^4b^2 - 4a^4d^2 - 4a^2d^2 + 4a^2b^2 - 4a^2d^2 - 4d^2 \\\\ (4a^4d^2 - 4a^4d^2) + (8a^2d^2 - 4a^2d^2 - 4a^2d^2) + (4d^2 - 4d^2) + 4a^4b^2 + 4a^2b^2 \\\\ 4a^4b^2 + 4a^2b^2 \\end{gathered}$$ Then, we can substitute the radicand back into the quadratic formula and continue simplifying. $$\\begin{aligned} c \u0026amp;= \\frac{-(2a^2d+2d) \\pm \\sqrt{4a^4b^2 + 4a^2b^2}}{2(-a^2-1)} \\\\ c \u0026amp;= \\frac{-2d(a^2+1) \\pm \\sqrt{4a^4b^2 + 4a^2b^2}}{-2(a^2+1)} \\\\ c \u0026amp;= \\frac{-2d(a^2+1) \\pm 2ab\\sqrt{a^2+1}}{-2(a^2+1)} \\\\ c \u0026amp;= \\frac{d(a^2+1) \\mp ab \\sqrt{a^2+1}}{a^2+1} \\\\ c \u0026amp;= \\frac{d(a^2+1)}{a^2+1} \\mp \\frac{ab \\sqrt{a^2+1}}{a^2+1} \\\\ c \u0026amp;= d \\mp \\frac{ab \\sqrt{a^2+1}}{a^2+1} \\\\ c \u0026amp;= d \\mp \\frac{ab (a^2+1)^{\\frac{1}{2}}}{(a^2+1)^1} \\\\ c \u0026amp;= d \\mp ab(a^2+1)^{-\\frac{1}{2}} \\\\ c \u0026amp;= d \\mp ab \\cdot \\frac{1}{(a^2+1)^{\\frac{1}{2}}} \\\\ c \u0026amp;= d \\mp \\frac{ab}{\\sqrt{a^2+1}} \\end{aligned}$$ We can now reverse the temporary substitutions to give us a definition of the $x$-coordinate of the point of tangency on circle 1. $$\\begin{gathered} a = S_t \\qquad b = r_1 \\qquad c = x_i \\qquad d = x_1 \\\\ x_i = x_1 \\mp \\frac{S_t r_1}{\\sqrt{S_t^2+1}} \\end{gathered}$$ This equation is in terms of the slope of the tangent line, the $x$-coordinate of the center of circle 1, and the radius of circle 1. However, it\u0026rsquo;s important to note that the tangent\u0026rsquo;s slope is itself defined by other given values in the problem. Earlier, we manipulated the circle equation so that it was in terms of $y$, which allowed us to find its derivative with respect to $x$. We can substitute our definition of the $x$-coordinate of the point of tangency into this circle equation, allowing us to define the corresponding $y$-coordinate. $$y_i = \\pm \\sqrt{r_1^2-(x_i-x_1)^2}+y_1$$\nfinal external tangent model The slopes of the tangent lines, the $x$-coordinates of the points of tangency, and the $y$-coordinates of the points of tangency have all been defined in terms of the original parameters of the problem. By using the point-slope equation $f(x) = m (x - x_1) + y_1$, the final system of equations can be displayed: $$\\begin{aligned} S_t \u0026amp;= \\frac{(y_1-y_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2} \\pm (x_1-x_2)(r_1 - r_2)}{(x_1-x_2)\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2-(r_1 - r_2)^2} \\mp (y_1-y_2)(r_1 - r_2)} \\\\ x_i \u0026amp;= x_1 \\mp \\frac{S_t r_1}{\\sqrt{S_t^2+1}} \\\\ y_i \u0026amp;= \\pm \\sqrt{r_1^2-(x_i-x_1)^2}+y_1 \\\\ y \u0026amp;= S_t(x - x_i) + y_i \\end{aligned}$$ Unfortunately, because of the ambiguity of the plus-or-minus operators in the system of equations, two of the possible equations generated are not correct, and so the correct equations must be chosen manually.\n⑦ four lines generated by the external tangent system internal tangent lines ⑧ internal tangents of two circles The process for modelling the internal tangents to two circles is very similar to the process for external tangents. In figure 2, two similar triangles were used to write a ratio involving the radii and the hypotenuses. In figure 8, triangles $\\triangle C_1 P i_1$ and $\\triangle C_2 P i_3$ are similar because they share the vertical angle $\\theta$, and they both have a right angle. This allows us to equate the following ratios between corresponding sides: $$\\frac{r_2}{r_1}=\\frac{h_2}{h_1}$$ We can rewrite $h_2$ as $d-h_1$ and then solve for $h_1$: $$\\begin{aligned} \\frac{r_2}{r_1} \u0026amp;= \\frac{d-h_1}{h_1} \\\\ \\frac{h_1r_2}{r_1} \u0026amp;= d-h_1\\\\ h_1r_2 \u0026amp;= r_1d-r_1h_1\\\\ h_1r_2 +r_1h_1\u0026amp;= r_1d\\\\ h_1(r_2 +r_1) \u0026amp;= r_1d\\\\ h_1 \u0026amp;= \\frac{r_1d}{r_2 +r_1} \\end{aligned}$$ This definition of $h_1$ allows us to find $\\theta$ using trigonometry. We can express the sine of $\\theta$ as the ratio between the opposite side in the right triangle and the hypotenuse: $$\\sin{(\\theta)=\\frac{r_1}{h_1}}$$ Then, we can substitute for $h_1$ and solve for $\\theta$. $$\\begin{aligned} \\sin{(\\theta)}\u0026amp;=\\frac{r_1}{ \\frac{r_1d}{r_2 +r_1}} \\\\ \\sin{(\\theta)}\u0026amp;=\\frac{r_1(r_2 +r_1)}{r_1d} \\\\ \\sin{(\\theta)}\u0026amp;=\\frac{r_2 +r_1}{d} \\\\ \\theta\u0026amp;=\\arcsin{\\left(\\frac{r_2 +r_1}{d}\\right)} \\end{aligned}$$ Just like the external tangents, the angle of the internal tangents is simply the angle of $C(x)$, plus or minus the angle $\\theta$ (see figure 4{reference-type=\u0026ldquo;ref\u0026rdquo; reference=\u0026ldquo;fig:plusMinusTheta\u0026rdquo;}). Because we already found the angle of $C(x)$ (called $\\theta_C$) when we modeled the external tangents, we can use a similar formula as before: $$\\begin{aligned} \\theta_t \u0026amp;= \\theta_C \\pm \\theta \\\\ \\theta_C \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\\\ \\theta_t \u0026amp;= \\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\pm \\arcsin{\\left(\\frac{r_2 +r_1}{d}\\right)} \\end{aligned}$$ Then, because the tangent of the angle of a line equals the slope of the line, we can take the tangent of each side to find the slope of the internal tangent lines. $$S_t = \\tan{\\left(\\arctan{\\left( \\frac{y_1-y_2}{x_1-x_2} \\right)} \\pm \\arcsin{\\left(\\frac{r_2 +r_1}{d}\\right)}\\right)}$$ Finally, we can substitute $d$ with the formula for the distance between $C_1$ and $C_2$. $$S_t = \\tan{\\left(\\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 + r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)}$$ This is very similar to the formula for the slope of the external tangent lines. In fact, the sole difference between the formulas is that the external tangent equation uses the difference between the circles' radii, while the internal tangent equation uses the sum of the radii. $$\\begin{aligned} S_{\\text{outer tangents}} \u0026amp;= \\tan{\\left(\\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 - r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)} \\\\ S_{\\text{inner tangents}} \u0026amp;= \\tan{\\left(\\arctan{\\left(\\frac{y_1-y_2}{x_1-x_2}\\right)} \\pm \\arcsin{\\left(\\frac{r_1 + r_2}{\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}}\\right)}\\right)} \\end{aligned}$$ Conveniently, this difference is consistent throughout the rest of the problem. At no point during the problem-solving process involving the external tangents was the term $r_1-r_2$ separated or modified, which means that all we need to do to adapt our model to use for the internal tangents is to replace $r_1-r_2$ with $r_1+r_2$. Or, to represent both set of tangents in the same system of equations, we can use $r_1 \\pm r_2$.\nfinal model If we rearrange the previous system of equations for external tangent lines, as well as replace $r_1-r_2$ with $r_1 \\pm r_2$, the updated system of equations can be displayed. We can mathematically model tangent lines to two circles on the coordinate plane using the following system of equations:\n$$ \\begin{aligned} a \u0026amp;= x_1-x_2 \u0026amp; b \u0026amp;= y_1-y_2 \u0026amp; c \u0026amp;= r_1 \\pm r_2 \\end{aligned} $$\n$$\\begin{aligned} S_t = \\frac{b \\sqrt{a^2+b^2-c^2} \\pm ac}{a \\sqrt{a^2+b^2-c^2} \\mp bc} \\end{aligned}$$\n$$\\begin{aligned} x_i \u0026amp;= x_1 \\mp \\frac{S_t r_1}{\\sqrt{S_t^2+1}} \u0026amp; y_i \u0026amp;= \\pm \\sqrt{r_1^2-(x_i-x_1)^2}+y_1 \\end{aligned}$$\n$$\\begin{aligned} y \u0026amp;= S_t(x - x_i) + y_i \\end{aligned}$$\nNote that in each of the first three lines in the system of equations, there are one or more uses of the plus-or-minus or minus-or-plus operator. This means that there are $2^3=8$ possible linear functions that this system could generate, depending on which option (plus or minus) one chooses for each line in the system. Only four of these functions, however, will represent actual tangents, internal or external, to the circles.\nlimitations of the model As previously noted, the biggest limitation in this model is that it\u0026rsquo;s ambiguous: only half of the lines it produces are real tangent lines, so someone using the model would need to manually choose which set to use. There are some situations in which the model breaks \u0026ndash; for example, when one or more of the tangent lines would be vertical, the model produces an undefined slope.\nThe IB Diploma Programme Final Statistical Bulletin, May 2021 Assessment Session, page 8\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://hugo.roman.computer/tangents/","summary":"context In 2021 March, i had to write a paper called the \u0026ldquo;Extended Essay\u0026rdquo;, which was sort of the culminating work for the International Baccalaureate program at my high school. I was one of the 3.2% of candidates to write it under the \u0026ldquo;Mathematics\u0026rdquo; subject and one of 20% to earn an A for it!1 :D\nEven though it\u0026rsquo;s poorly written, i decided to throw it up here, with some of the cruft trimmed off.","title":"📐 graphing tangent lines to two circles"},{"content":" ","permalink":"https://hugo.roman.computer/password_security/","summary":" ","title":"🔑 a talk about password security"},{"content":" I wanted to recreate MF DOOM's prose not only because he's my favorite artist but also because it's famously dense with rhyme, wordplay, and pop culture references. ChatGPT can already generate lyrics as \u0026ldquo;complex\u0026rdquo; as Lil Pump\u0026rsquo;s using zero-shot prompting, but is it possible to use more sophisticated methods to coax a language model into generating lyrics of MF DOOM's caliber?\ndemo Unfortunately, even with fine-tuning, MF FOOM doesn\u0026rsquo;t quite match DOOM's wordsmithery.\nExample input prompt:\nA song titled \u0026quot;Metal Mask\u0026quot; about the story of how MF DOOM obtained his iconic metal mask and the power it gives him in the rap game.\nFinal output song:\nLyrics:\nMetal mask give him bad brains, pain man can't explain\nGot locked up like a zoo monkey, then poof! Freedom\nGot loose, left the cell, started rockin fools clean\nLike a hill of beans, beans, no pan dulce\nThe rap game is like the seventh seal, it's so real\nHe hide behind a mask like a child, it's cold steel\nNo regrets, he do what he gotta and he peep this\nI hold this, zap! Straight out the box, no joke\nDeadly as a runaway stampede or lightning bolt in Summertime\nBig as a Bumblebee sting and quicker to bring strife\nThrough the big speakers, sound bombs, ignite drama\nOn my A-game, I be straight sniper, through your eye likeGrey's\nAnatomy\nWhite chick that be in the show with all them doctors\nKnow what I'm saying? The name control the ball like gridiron\nSpeech, diction, syntax is triple A rated\nAnd it's not how he talk it, who he talk to\nTo all y'all that hate, keep your mouth closed\n(DOOM!) Watch the mask and you'll see\nAnd say your prayers, like \u0026quot;Boom! He's back!\u0026quot;\nYou won't see me, I disappear like Dr. Jekyll and Mr. Hyde\nBoogie blow, snatch the dough then split like Houdini\nLike a palm tree in Africa, can't stand still\nWith the metal mask, give him mad-r'dic skills\nLike Kung Fu, uncanny too and always get it poppin'\nAlways gone, always goon, on the road that's how it seem\nSeriously, he be writing on the tour like Forrest Gump\nWent to dinner with the 'mentor', it was crazy dude\nHe gave him advice, he told him what life was about\nWe got beef with Jim Crow and don't forget\nThe name is DOOM, the mask gives him powers\nCompare that to the first few lines of DOOM's All Caps:\nSo nasty that it's probably somewhat of a travesty having me\nDaily told the people \u0026quot;You can call me Your Majesty!\u0026quot;\nKeep your battery charged\nYou know it won't stick, yo\nAnd it's not his fault you kick slow\nShould've let your trick 'ho chick hold your sick glow\nPlus nobody couldn't do nothin' once he let the brick go\ntechnical process grabbing DOOM\u0026rsquo;s lyrics I started by downloading the lyrics of every DOOM song from Genius (a website where users transcribe and annotate song lyrics) using the LyricsGenius Python library.\nfrom lyricsgenius import Genius import os import re token = os.getenv(\u0026#34;GENIUS_API_KEY\u0026#34;) genius = Genius(token) # If the song title contains any of these words, it will be excluded from the # results. genius.excluded_terms = [\u0026#34;remix\u0026#34;, \u0026#34;mix\u0026#34;, \u0026#34;live\u0026#34;, \u0026#34;instrumental\u0026#34;] artist = genius.search_artist(\u0026#34;MF DOOM\u0026#34;) # Clean up the lyrics. songs = {} for song in artist.songs: songLyrics = re.sub(r\u0026#39;^\\d* Contributors?.* Lyrics\u0026#39;, \u0026#39;\u0026#39;, song.lyrics) songLyrics = re.sub(r\u0026#39;You might also like\u0026#39;, \u0026#39;\u0026#39;, songLyrics) songLyrics = re.sub(r\u0026#39;\\d*Embed\u0026#39;, \u0026#39;\u0026#39;, songLyrics) songs[song.title] = songLyrics songs Searching for songs by MF DOOM... Song 1: \u0026#34;Doomsday\u0026#34; Song 2: \u0026#34;Beef Rapp\u0026#34; Song 3: \u0026#34;Rapp Snitch Knishes\u0026#34; Song 4: \u0026#34;One Beer\u0026#34; ... Done. {\u0026#39;Doomsday\u0026#39;: \u0026#39;[Intro: Pebbles the Invisible Girl, MF DOOM]\\nMic Check\\nWhen I was... \u0026#39;Beef Rapp\u0026#39;: \u0026#39;[Produced by Metal Fingers]\\n\\n[Skit 1]\\nNow I haven\\\u0026#39;t eaten a... \u0026#39;Rapp Snitch Knishes\u0026#39;: \u0026#39;[Intro: Mr. Fantastik \u0026amp; MF DOOM]\\nYo! Yo!\\nMF DOOM, M... \u0026#39;One Beer\u0026#39;: \u0026#39;[Intro]\\nI get no kick from champagne\\nMere alcohol doesn\\\u0026#39;t thr... fine-tuning GPT-3 I used the ChatGPT API to generate one-sentence summaries of each song. These are used to create a list of prompt\u0026ndash;completion pairs for fine-tuning a different model, using OpenAI\u0026rsquo;s recommendations for formatting best practices:\n{ \u0026#34;prompt\u0026#34;: \u0026#34;\u0026lt;song summary\u0026gt;\\n\\n###\\n\\n\u0026#34;, \u0026#34;completion\u0026#34;: \u0026#34; \u0026lt;song lyrics\u0026gt;\\nEND OF SONG\u0026#34; } import openai import jsonlines openai.organization = os.getenv(\u0026#34;OPENAI_ORG\u0026#34;) openai.api_key = os.getenv(\u0026#34;OPENAI_API_KEY\u0026#34;) prompts = [] for title, lyrics in songs.items(): if lyrics == \u0026#34;\u0026#34; or lyrics == None: continue response = openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant who is an expert on pop culture, and specifically the history of hip hop.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#39;Please give a one-sentence summary of the following song. Your response should follow this format: \u0026#34;A song about \u0026lt;description\u0026gt;.\u0026#34;. Here are the lyrics:\\n\\n\u0026#34;\u0026#34;\u0026#34;\\n\u0026#39; + lyrics + \u0026#39;\u0026#34;\u0026#34;\u0026#34;\u0026#39;}, ] ) description = response[\u0026#39;choices\u0026#39;][0][\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;] description = re.sub(r\u0026#39;^A song about \u0026#39;, \u0026#39;\u0026#39;, description) description = f\u0026#39;A song titled \u0026#34;{title}\u0026#34; about {description}\u0026#39; prompts.append({ \u0026#34;prompt\u0026#34;: description + \u0026#34;\\n\\n###\\n\\n\u0026#34;, \u0026#34;completion\u0026#34;: \u0026#34; \u0026#34; + lyrics + \u0026#34;\\nEND OF SONG\u0026#34; }) # Write the prompt-completion pairs to a JSON Lines file. with jsonlines.open(\u0026#39;prompts.jsonl\u0026#39;, mode=\u0026#39;w\u0026#39;) as writer: writer.write_all(prompts) prompts[0] {\u0026#39;prompt\u0026#39;: \u0026#39;A song titled \u0026#34;Doomsday\u0026#34; about the power and impact of an MC, their unique and influential voice in the world of hip hop.\\n\\n###\\n\\n\u0026#39;, \u0026#39;completion\u0026#39;: \u0026#39; [Intro: Pebbles the Invisible Girl, MF DOOM]\\nMic Check\\nWhen I was led to you\\nI knew you were the one for me... \\nEND OF SONG\u0026#39;} I then fine-tuned a GPT-3 DaVinci model using the song lyrics and summaries. I had to wait in line to fine-tune my mode for hours, even though the fine-tuning process itself took just five minutes.\n!openai api fine_tunes.create -t prompts.jsonl -m davinci making him sing After the model was finished fine-tuning, MF FOOM had a pen! I put him to work with his first song, Metal Mask.\ndef songDescriptionToLyrics(description): prompt = description + \u0026#34;\\n\\n###\\n\\n\u0026#34; # Retrieve the ID of the latest fine-tuned model you\u0026#39;ve created. model = dict(openai.FineTune.list())[\u0026#39;data\u0026#39;][-1][\u0026#34;fine_tuned_model\u0026#34;] if model == None: raise Exception(\u0026#34;The fine-tuning job probably hasn\u0026#39;t finished yet.\u0026#34;) completion = openai.Completion.create( model=model, prompt=prompt, max_tokens=1300, temperature=0.9, presence_penalty=0.46, stop=\u0026#34;END OF SONG\u0026#34; ) return completion[\u0026#39;choices\u0026#39;][0][\u0026#39;text\u0026#39;] print(songDescriptionToLyrics(\u0026#39;A song titled \u0026#34;Metal Mask\u0026#34; about the story of how MF DOOM obtained his iconic metal mask and the power it gives him in the rap game.\u0026#39;)) Metal mask give him bad brains, pain man can\\\u0026#39;t explain Got locked up like a zoo monkey, then poof! Freedom Got loose, left the cell, started rockin fools clean Like a hill of beans, beans, no pan dulce The rap game is like the seventh seal, it\\\u0026#39;s so real ... I then used ElevenLabs to give him a voice. This a service which enables you to generate incredibly realistic text-to-voice audio clips, and one of its features is the ability to clone someone's voice from an existing audio clip and get the resulting voice engine to read out loud any new text you want.\nI cloned DOOM's voice from the acapella version of Gazzillion Ear, then generated the vocals for Metal Mask using the clone with a \u0026quot;stability\u0026quot; value of 86% and a \u0026quot;similarity\u0026quot; value of 100%. Finally, i used GarageBand to overlay the vocals onto the instrumental of Gazzillion Ear.\nHe doesn't sound exactly like DOOM, and his flow is off-beat, even after i played around with quantization. Oh well. He's still a better rapper than me.\nThe lyrics i generated and the final song Metal Mask are a non-commercial parody.\n","permalink":"https://hugo.roman.computer/mf_foom/","summary":"I wanted to recreate MF DOOM's prose not only because he's my favorite artist but also because it's famously dense with rhyme, wordplay, and pop culture references. ChatGPT can already generate lyrics as \u0026ldquo;complex\u0026rdquo; as Lil Pump\u0026rsquo;s using zero-shot prompting, but is it possible to use more sophisticated methods to coax a language model into generating lyrics of MF DOOM's caliber?\ndemo Unfortunately, even with fine-tuning, MF FOOM doesn\u0026rsquo;t quite match DOOM's wordsmithery.","title":"🎤 MF FOOM: AI-generated MF DOOM songs"},{"content":"context This is a paper i wrote for my Government course; it\u0026rsquo;s about current and imminent issues about AI and how local regulators should deal with them. It\u0026rsquo;s not as epistemically rigourous or entertaining as i\u0026rsquo;d normally shoot for for a blog post, but i figured i\u0026rsquo;d post it here anyway. It also doesn\u0026rsquo;t cover the extreme issues i care more about: existential risks from artificial superintelligent agents and the risk of astronomical amounts of suffering from conscious AI systems.\noverview The field of artificial intelligence (AI) has seen rapid advancements in recent years, forcing citizens and regulators alike to ponder what new rules should be implemented to ensure that the technology brings as much benefit to society, and as little harm, as possible. This report will provide an overview of how different state governments in the US are regulating AI, as well as the technical details necessary to understand the issues this rapidly evolving technology might cause.\nFundamentally, artificial intelligence refers to machines that possess the ability to reason, learn, and execute tasks that are typically performed by humans. In its early stages, these machines were manually programmed, and their creators focused on rule-based systems and expert knowledge. Over the years, the field has undergone two boom–bust cycles, with periods of rapid advancements followed by stagnation (“AI winters”). Today, it has transformed significantly with the advent of deep learning, a technique that involves iteratively updating the weights of a large neural network by exposing it to large amounts of data.\nDeep learning has enabled AI systems to automatically perform a diverse array of impressive tasks that many used to think were impossible for a machine to do, from generating text, code, and images, to operating vehicles in real-world environments, to detecting and categorizing objects in photos. This has brought on a surge of interest in the field, creating a positive feedback loop of new capabilities and increased funding.\nFunding of artificial intelligence in the US has been increasing exponentially over time.1\nHowever, these novel capabilities bring with them novel legal challenges to consider: for example, how should states regulate companies who collect user data to train new AI models, or employers who use AI systems to choose which candidates to hire when those systems might have systematic biases? Potential issues, which will be expanded on in a later section, include\nCopyright of the data used to train AI models Privacy of the users who generate data Biases in models which reflect the data used to train them Reliability in safety-critical applications Interpretability of models Adversarial attacks Empowering rogue bad actors Displacement of jobs due to AI-enabled automation In its present state, the set of local regulations relating to artificial intelligence does not reflect this multitude of forthcoming, and current, issues. This is because the technology sector famously races faster than regulators can keep up with, and AI is no exception. As of May 2023, only four state bills have been enacted which relate to artificial intelligence:\nA Georgia bill which appropriates funds across a variety of sectors and includes a $65 million grant to expand AI manufacturing across the state A New Mexico bill which also appropriates funds and includes a grant for an academy charter school to purchase artificial intelligence equipment A North Dakota bill relating to the definition of personhood, which excludes (among other entities) artificial intelligence systems A West Virginia Bill creating a pilot program relating to the optimization of roads, which will use machine learning (ML) to assess them With the exception of the North Dakota personhood bill, none of these local regulations address the most fundamental issues related to AI going forward. The vast majority of local regulations on AI are yet to come.\nThe vast majority of AI-related bills in the US are in the pending stage.\nStates such as New York and Massachusetts have or are considering the largest number of AI-related bills.\nHowever, when the number of bills that a state considers overall is taken into account, New Mexico and Washington top the list as the most forward-thinking in this regard.\na diverse set of challenges It is crucial to understand the basic nature of deep learning in order to reason about how to regulate the field going forward. Deep learning works by starting with a layered “blank slate” neural network, which is a collection of weighted variables connected in a way that roughly models the structure of biological brains. This network takes a set of numbers as input, passes them through a complicated series of functions governed by the weights, and returns a different set of numbers as output. During the training phase of the creation of an AI model, the model is taught which outputs it should produce when fed different inputs. For example, if a researcher wants to teach a machine learning model how to differentiate images of cats versus dogs, they will first convert each image into a set of numbers corresponding to the image’s pixel values and then show to the model each set as well as what animal the set corresponds to. With each image the model is shown, its weights are updated according to an algorithm known as gradient descent. This encodes the knowledge about what differentiates dogs and cats in the weights.\nIn short, modern machine learning models learn much in the same way that humans do: they begin with no knowledge or biases and are shown thousands of examples of the desired behavior. After the learning process, novel inputs can be fed into the model to produce corresponding outputs. This basic process can be used to create models which can do anything from predicting the stock market to recognizing faces to generating text, and having a basic understanding of this process helps us understand the AI-related issues that regulators face.\nheaps of data: copyright, user privacy, and bias Because modern AI systems are trained using examples of desired input and output, they require a lot of data to be trained. For example, the model powering ChatGPT was trained using 570 gigabytes of data obtained from books, blogs, Wikipedia, articles, and other writings on the internet.2 By the very nature of the process of collecting data to use for training, machine learning engineers cannot get permission from each of the millions of authors who produced the content making up the data. This was made clear to Stability AI – the company behind the AI art generator Stable Diffusion – after they faced backlash from the visual artists who created the millions of images that the company used to train their model.3\nThe more data a company has access to, the more powerful of a model it can create. This creates a strong financial incentive to collect more data from its users. However, many users don’t want companies to collect and store every bit of information they give to a service. Not only does it feel creepy, but data breaches also happen constantly, which expose private details from a company’s servers to the public.\nFinally, because AI models learn from being shown examples from the data, they pick up the biases that it contains. For example, in 2018, Amazon developed a model to vet candidates who applied for roles at the company. Because it was trained on previous hiring patterns, the model was unfairly skewed in favor of male candidates. Amazon subsequently scrapped the model. Out of all the proposed AI-related state bills, regulations to prevent automated decision-making from being discriminatory are especially popular. New Jersey alone is considering three pending bills of this nature.4\ninscrutable matrices: reliability, interpretability, and adversarial training The structure of modern AI systems is different from that of hand-coded programs and human brains in such a way that makes them less interpretable, less reliable, and vulnerable to adversarial attacks.\nInstead of programs written in plain English, they are inscrutable matrices trained on trillions of bytes of data. This makes it difficult to make guarantees about how often they will make mistakes. For example, despite the impressive capabilities of large language models (LLMs) like ChatGPT, they’re still susceptible to what is called “hallucinations”, or making up facts and rationalizing them to the end user.\nBecause AI models work probabilistically, researchers cannot prove anything about the behavior of deep learning systems – they can only run tests. For safety-critical applications, this might not be acceptable. For example, one of the reasons we don’t see more self-driving cars on the road today is that the reliability of humans is hard to beat. In “Humans are very reliable agents”, Alyssa Vance writes:\n…human drivers are ridiculously reliable. The US has around one traffic fatality per 100 million miles driven; if a human driver makes 100 decisions per mile, that gets you a worst-case reliability of ~1:10,000,000,000 or ~99.999999999%. That\u0026rsquo;s around five orders of magnitude better than a very good deep learning model…\nThis doesn’t mean that deep learning models are inherently less reliable than humans in all domains – humans are probabilistic too and suffer their own set of inconsistencies, like cognitive biases and poor reaction time. But for applications like self-driving cars, not all algorithms are at the desired level of reliability yet.\nAnother consequence of the structure of deep learning systems is that they are susceptible to adversarial attacks, which include what are known as data poisoning and evasion attacks. Data poisoning makes use of the fact that the performance of a model is dependent on the quality of the data it was trained on. If the data is user-generated, a malicious actor can “poison” it by injecting faulty data into the training set. One example of this is a backdoor attack, whereby poisoned data influences the model to act in a certain way when it is fed an input with a particular “trigger” (like an imperceptible defect in an image).5\nIn evasion attacks, a malicious actor alters an input in just the right way so that it bypasses a machine learning model meant to detect undesired content. For example, Christopher Back et al. discovered techniques to alter hateful Twitter posts to bypass hate speech detection algorithms without altering the semantic meaning of the posts.6\nA computer vision model which detects stop signs is deceived by an adversarially modified stop sign (right). A specially crafted pattern placed over the stop sign tricks the model into believing the sign is 80% likely to be a sports ball.7\nAll digital systems are susceptible to errors and targeted hacking attacks, including AI systems. Looking ahead, local regulators should establish standards for the reliability and security of AI applications which could put at risk the private data and physical safety of millions of users. However, while it’s important that local regulators establish safety standards, they should be wary about imposing overbearing restrictions or not coordinating with regulators in other localities, since this risks slowing down the adoption of new AI technologies and consequently reducing the positive effect they will have on the locality’s economy. For example, two autonomous driving entrepreneurs share their struggles trying to expand their service to multiple cities in the US:8\nSince the state and the federal governments had limited guidance on the deployment of autonomous driving services, we had to deal with each city individually to expand our operation, which is an inefficient and costly process given the regulatory differences among cities. In our cases in the U.S., the test data and safety assurance plans in California did not give us privileges when we applied for the test permit in Indiana. Although such an arrangement may be adequate to mitigate people’s safety risk in different states with different traffic densities, there could be room to improve process standardization and transparency, which would save AI start-ups’ resources and, in turn, help advance the technology.\nemerging abilities: unpredictability, rogue actors, and job displacement The final set of AI-related issues that regulators will have to confront has to do with the emerging capabilities of cutting-edge models. While these are the capabilities that will revolutionize society and potentially improve the welfare of billions, they’re also difficult to predict and can be harmful if they empower rogue parties with malicious intentions.\nCompared to other technologies, the emerging capabilities of AI models are incredibly difficult to predict. The website Metaculus enables users to ask questions about the future and register their predictions about other users’ questions.9 According to a 2023 report, out of all categories of questions, the category which tended to result in the least accurate predictions (that is, the one which is most difficult to make predictions about) was artificial intelligence.10 Additionally, according to a paper from 2022 investigating the emerging capabilities of large language models as they are scaled up, these capabilities “cannot be predicted simply by extrapolating the performance of smaller models”.11\nThis means that regulators must think ahead. They cannot create laws based on the current capabilities of artificial intelligence and the harm it causes. Rather, they must proactively reason about what these models may be capable of in the future and create the necessary legal structures to prepare for them.\nIn 2020, Deepmind (an AI research group in Google) created the system AlphaFold, which predicts the three-dimensional structure of a folded protein based on its amino acid sequence. This system smashed the record in the bi-annual CASP contest, in which a hundred research groups from across the world compete to create the system which most accurately completes this task.12 This was a revolutionary feat in the field of computational biology, and it demonstrated how surprisingly powerful AI had become.\nHowever, even though AlphaFold and advancements like it will help society develop better medicine, streamline transportation, and improve people’s quality of life overall, these new capabilities will cause harm when malicious actors have access to them. For example, anyone can automate the generation of misinformation to post on social media to influence the public’s opinions, and language models which can code will empower hacking groups to break the security of the companies and governments who can’t keep up. Roman Hauksson et al. demonstrated that language models can be trained to make more accurate guesses of people’s passwords based on information in their public social media profiles.13\nThe fundamental difference between AI and other potentially dangerous technologies is how accessible it is. Advancements in our understanding of nuclear engineering, for instance, have generally been kept safe because the procurement of materials used to physically manufacture nuclear bombs is highly visible and requires the coordination of different entities which are subject to regulation. In short, it hasn’t proved much of a challenge for governments to prevent individuals from producing nuclear bombs. Machine learning, however, is much more broadly useful than nuclear engineering, and the risks it might pose are less obvious, so more actors have been incentivized to research the field, and they have been more open about it, than nuclear engineering. There is a strong culture of open-access research in machine learning: almost every researcher uploads preprints of their papers to the open-access repository arXiv before they are peer-reviewed.14 This means that, unlike many other academic fields, potentially dangerous new applications are easily accessible.\nA bad actor would have a hard time getting access to the necessary materials to construct a nuclear bomb. But the materials necessary to run most AI models are almost everywhere: computers. On February 23rd, 2023, Meta AI (Formerly Facebook AI) announced the development of a large language model called LLaMA and openly released the code they used to train it. Access to the weights defining the final trained model, which cost millions of dollars to produce, was granted on a case-by-case basis to researchers who applied. However, one week after the code was released, a researcher anonymously leaked the weights of the model for the public to download, enabling anyone to run it on their personal computers.15 This demonstrates how difficult it is to control the proliferation of artificial intelligence technology.\nLocal regulators have to account for the unpredictable nature of AI advancements as well as the difficulty in controlling access to them, but they will also have to take into account the effect it will have on the economy and particularly, the automation of labor.\nA report from March of this year by OpenAI (the creators of ChatGPT) titled “GPTs are GPTs” claims that language models like GPT-3 (which stands for Generative Pre-trained Transformer) are General-Purpose Technologies, meaning that they will affect the entire economy as opposed to individual sectors within it.16 Previous examples of GPTs include the steam engine, electricity, and information technology – these are innovations that increased the productivity of workers from a diverse set of fields. According to the report, “around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted.” Additionally, high-income, white-collar jobs are projected to see the most impact due to LLMs.\nLocal regulators should exert extra effort when creating laws regulating GPTs like AI because of their particular importance. The regulators may face pressure from local workers and unions to limit the proliferation of job automation technology due to the risk it poses to the workers it might displace, such as the truck drivers which self-driving trucks are expected to replace.17 However, localities that impose more restrictions on the automation of work in their area may not reap as many economic gains as those who embrace the changing labor landscape at the cost of short-term worker displacement. The general attitude among economists is that advancements in technology tend not to affect employment rates in the long term.18\nconclusion The field of artificial intelligence is rapidly evolving, offering humanity a plethora of new solutions. However, these emerging capabilities are difficult to predict ahead of time and bring with them risks from rogue actors. Like any digital technology, AI systems are also imperfect, in that they are not 100% reliable, they are vulnerable to adversarial attacks, and they pick up on the biases in the data used to train them. Unfortunately, while most US states are considering bills to address these issues, local regulators are still behind the curve. They should anticipate future advancements and risks from AI and preemptively enact laws to address them, while at the same time being careful not to stifle the economic and social benefits of increased automation.\nhttps://www.statista.com/statistics/943151/ai-funding-worldwide-by-quarter/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.sciencefocus.com/future-technology/gpt-3/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.forbes.com/sites/kenrickcai/2022/09/07/stability-ai-funding-round-1-billion-valuation-stable-diffusion-text-to-image/?sh=76026a4124d6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.ncsl.org/technology-and-communication/artificial-intelligence-2023-legislation\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://proceedings.mlr.press/v139/schwarzschild21a.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/ACM-Research/HateDeception_public\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/1804.05810\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n​​https://arxiv.org/ftp/arxiv/papers/2112/2112.09325.pdf\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.metaculus.com/home/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://forum.effectivealtruism.org/posts/JN6wm6u5MMmqwdnEs/metaculus-predictions-are-much-better-than-naive-base-rates\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2206.07682\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://alphafold.ebi.ac.uk/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/ACM-Research/targeted-password-guesses\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://ezramagazine.cornell.edu/FALL12/CoverStorySidebar2.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.theverge.com/2023/3/8/23629362/meta-ai-language-model-llama-leak-online-misuse\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://arxiv.org/abs/2303.10130\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.sciencedirect.com/science/article/pii/S0160791X21002074\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n​​https://www.worldbank.org/en/publication/wdr2019\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://hugo.roman.computer/local_ai_regulation/","summary":"context This is a paper i wrote for my Government course; it\u0026rsquo;s about current and imminent issues about AI and how local regulators should deal with them. It\u0026rsquo;s not as epistemically rigourous or entertaining as i\u0026rsquo;d normally shoot for for a blog post, but i figured i\u0026rsquo;d post it here anyway. It also doesn\u0026rsquo;t cover the extreme issues i care more about: existential risks from artificial superintelligent agents and the risk of astronomical amounts of suffering from conscious AI systems.","title":"⚖️ local regulation of artificial intelligence in the US"},{"content":"What\u0026rsquo;s the point of an interest-specific social club? To socialize, of course! With people who share a specific interest. I would argue this isn\u0026rsquo;t as obvious to people-organizers as it might sound.\nLast Friday, I attended a meetup with my university\u0026rsquo;s philosophy club. I went in expecting many opportunities to meet other thoughtful people, but I left the main event without seeing them. Instead, the meetup was a guided large group discussion about quotes from Emerson. While I did learn a lot by following the conversation, and it was somewhat entertaining, I was disappointed that I didn\u0026rsquo;t have the chance to engage in more personal conversations and get to know the other members of the club.\nIf you get to decide what ~15 thoughtful people will do for two hours on a Friday afternoon, this is a rare opportunity, and you should be strategic about it. It represents 30 synchronous human-hours of opportunity cost, plus transportation. While you could use these hours to help people learn more about philosophy, I don\u0026rsquo;t think this is the best use for the time. Rather, I believe human connection is more important. I could have learned about Emerson much more efficiently by reading the Stanford Encyclopedia of Philosophy, or been entertained more efficiently by taking a trip to an amusement park, for two hours. But instead, I blocked out that time because meeting the right person could have a huge positive impact on my life. I might make a great friend. We might spend a lot of quality time in the future. They could be a future romantic partner, or a professional connection. Indeed, I won\u0026rsquo;t have a better opportunity to meet lifelong friends than in college – in no other point of my life will I have as much time at my disposal to socialize and be in the same physical location as so many similar people in the same position. Meeting people has a huge mutual return on time investment.\nsmall group discussions are more fun and facilitate more interpersonal connections With this motivation in mind, how does one facilitate better mingling? My suggestion: structure your meetup to encourage small group discussions.\nMost people prefer talking to listening. The fewer people present in a conversation, the more space each person has to talk. (amount of talking)/(number of people) is larger, making the conversation more enjoyable. Smaller discussion groups give each person more control over the flow of the conversation, which also makes it more enjoyable. It\u0026rsquo;s easier to interject about things that you find interesting and ask questions about things you don\u0026rsquo;t know about. Talking to a smaller group allows you to speak less reservedly. It allows people to be more vulnerable and talk about things that have more personal significance. I see this as vital for interpersonal bonding. Smaller groups tend to talk about things that have less broad appeal. They give people the room to talk about more personal things and tell stories and anecdotes. Tautologically, you have to learn about the people around you to get to know them. how to encourage small group discussion One big conversation can be an equilibrium of your social event, depending on how you engineer the environment. I call this the \u0026ldquo;committee\u0026rdquo; style of conversation, and I see it as a failure mode. Once it reaches this point, it\u0026rsquo;s awkward to split it up. You have to find an opportunity to begin a private conversation with the people next to you, which can feel like talking over the person who\u0026rsquo;s currently speaking in the large group. Most people aren\u0026rsquo;t agentic or brash enough to step in the middle of the circle and announce \u0026ldquo;Okay guys, let\u0026rsquo;s split this conversation up. People on this side, go over here, and people on this side, stay here! 🤓\u0026rdquo;.\nSo you have to coordinate from the onset if you want a better conversation structure. Here are some ideas.\nInvite enough people so it can\u0026rsquo;t become a committee in the first place. A circle of 25 people would be so awkward and ridiculous that people will be forced to break off. Host the event in a place with enough room for people to spread out. Ideally, there will be different rooms or partly sheltered areas for some insulation between groups. If you\u0026rsquo;re the host, maybe it isn\u0026rsquo;t so brash to manually split up a large group if it forms. You could, for example, instruct guests to move to a different group when they hear a bell you ring every 30 minutes. This might bring a \u0026ldquo;forced\u0026rdquo; vibe to the party, but it also gives people plausible deniability when they want to leave a conversation. If they\u0026rsquo;re engaged, they\u0026rsquo;re totally allowed to ignore the bell and continue the conversation. But if they\u0026rsquo;re bored, they can say \u0026ldquo;Sorry, looks like I have to move to a new group. What can you do? But it was nice meeting you!\u0026rdquo;. putting my money where my mouth is I don\u0026rsquo;t make this post to rag on the organizer of the philosophy club, or anyone else who has held a suboptimal social gathering. In fact, after the event, I pulled the philosophy club leader aside after the meeting to give him my thoughts constructively, and he was receptive to experimenting with a different structure for the next meeting. Different hosts have different goals for their events, and that\u0026rsquo;s fine. I just value human connection a lot. It brings me a lot of joy when I witness two people meet and get along well because of something I initiated. I\u0026rsquo;m not trying to be cheesy – it genuinely makes me super excited when I hear I\u0026rsquo;ve created a friendship.\nI\u0026rsquo;ve attended many social meetups in college so far, but recently I decided to step up and host two of my own, and my third and most ambitious is coming up in a few weeks. With each iteration, I\u0026rsquo;ve changed things to facilitate more interpersonal connection. The first party was awkward, reserved, and small, and I was late because I didn\u0026rsquo;t give myself enough time to prepare the food. The second was bigger, and I was ecstatic to see banter, deep conversation, and people exchanging contact information before they left, but it went too late into the night and still had a bit of a committee feel. The upcoming event will have even more people, take place in a small building with partially insulated rooms to break up potential committees, and have a definitive closing point.\nI hope this post inspired you to think critically about how to help people meet each other. Those with an entrepreneurial spirit towards socializing, go forth and foster connections!\n","permalink":"https://hugo.roman.computer/discussions/","summary":"What\u0026rsquo;s the point of an interest-specific social club? To socialize, of course! With people who share a specific interest. I would argue this isn\u0026rsquo;t as obvious to people-organizers as it might sound.\nLast Friday, I attended a meetup with my university\u0026rsquo;s philosophy club. I went in expecting many opportunities to meet other thoughtful people, but I left the main event without seeing them. Instead, the meetup was a guided large group discussion about quotes from Emerson.","title":"💬 avoid large group discussions in your social events"},{"content":"multi-factor authentication When you sign into an online service, you\u0026rsquo;re required to provide a username to identify who you are and a password to prove that you are who you say you are. Anyone can claim that they\u0026rsquo;re romanhn on GitHub, but only I know my GitHub password. But if a hacker breaches GitHub\u0026rsquo;s servers and publishes a list of everyone\u0026rsquo;s password,1 knowing my password is no longer proof of anything. This is the motivation behind two- or multi-factor authentication (MFA): to access my GitHub account, not only would you have to know my password, but you\u0026rsquo;d need to authenticate yourself using an additional factor, like tapping a notification on my phone.\nadapted from sketchplanations\nI\u0026rsquo;ll use the \u0026ldquo;Swiss cheese model\u0026rdquo;, shown above, to explain how multi-factor authentication provides security through redundancy. If a hacker can bypass one hole (knows my password) they have to find a hole in another layer (get me to tap the notification) in order to hack my account.\ncategories of factors A user can use any of three categories of factors to authenticate themself:2\nA piece of information only they know, like a password or PIN. A physical object only they possess, like a key or security token. A physical characteristic only they display, like a fingerprint or voice pattern. Each layer should be a different category because different factors in the same category are often breached simultaneously, as if they were sliced from the same section of the cheese block so their holes were in similar places. For example, if I fell victim to a phishing attack, the hacker would discover all the \u0026ldquo;pieces of information only I know\u0026rdquo; in one fell swoop. Asking the hacker \u0026ldquo;what was the name of your first pet?\u0026rdquo; doesn\u0026rsquo;t provide any additional security if they discovered my password and my first pet\u0026rsquo;s name at the same time.\nThis is the same idea behind the 3-2-1 rule for backing up data.\nYou should maintain three copies of anything you care about: two copies in different formats and one off-site backup.\nLike with authentication, redundancy in backups is best when it is spread across different modalities. Instead of protecting against a phishing attack, however, it prevents a house fire from wiping out your baby photo collection because you never stored a copy in the cloud.\nthe problem with MFA While MFA makes it harder for a hacker to breach an account, it also makes it easier for a legitimate user to get locked out. People lose their cell phones and biometric sensors fail, all the time. And this matters because getting locked out is often worse than your account being hacked – I would rather let a hacker download all of the data in my Google Photos account than lose access to it permanently.\nSuppose that a laptop can be accessed using three authentication factors (entering a password, confirming via an SMS text, and scanning a fingerprint), and they each have false positive (hacker successfully bypasses) and false negative (a user fails to pass) rates of 1%. Different multi-factor authentication schemes combining these factors have new rates, as shown by the confusion matrices below.3\nonly password required user access granted access denied legitimate 99.00% 1.00% hacker 1.00% 99.00% password and SMS required user access granted access denied legitimate 98.01% 1.99% hacker 0.01% 99.99% password, SMS, and fingerprint required user access granted access denied legitimate ~97.03% ~2.97% hacker 0.0001% 99.9999% With each additional factor, the chance that a hacker could successfully break in decreases exponentially (1% -\u0026gt; 0.01% -\u0026gt; 0.001%). However, the chance that a legitimate user gets locked out increases ~linearly (1% -\u0026gt; 1.99% -\u0026gt; ~2.97%). The probability that \u0026ldquo;something bad happens\u0026rdquo; is actually greater when three factors are required instead of two.4\nthe 2/3 rule To combat against false negatives and false positives simultaneously, I propose the \u0026ldquo;2/3 rule\u0026rdquo; for multi-factor authentication:\nA system should have in place three methods, in different modalities, for authenticating a legitimate user. The user is granted access to the system as long as they can pass at least two out of the three methods.5\nThis provides redundancy on both fronts: a malicious actor must crack at least two methods to breach an account, and a legitimate user must fail at least two methods to be locked out. It\u0026rsquo;s like a castle with a moat and cannons to thwart invaders, as well as guardrails and nets to prevent the king from falling into the moat.\nThe confusion matrix for this combination demonstrates how the 2/3 strategy provides symmetric redundancy:\nat least two of password, TOTP, or fingerprint user access granted access denied legitimate ~99.97% ~0.03% hacker ~0.03% ~99.97% While the chance that a hacker breaks into a 2/3 system is higher than the original 2- or 3-factor systems (~0.03% \u0026gt; 0.01% \u0026gt; 0.0001%), the chance that a user gets locked out is dramatically lower, even more so than the 1-factor system (0.03% \u0026lt; 1.00%). This means that the overall chance of being hacked or locked out is lower than any other system.\nthis is nothing new That being said, this strategy is already in use; I just wanted to give a name to it. For example, if you have 2-factor authentication enabled on your Google or Facebook accounts, they will allow you to receive a code from a text message in case you don\u0026rsquo;t have your TOTP generator on you.\nOkay, a more realistic situation is \u0026ldquo;a hacker breaches GitHub\u0026rsquo;s servers, downloads a list of everyone\u0026rsquo;s password hashes, cracks the easiest ones, and sells the list to another hacker on some forum\u0026rdquo;, but the same idea holds.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThere are other categories like \u0026ldquo;somewhere you are\u0026rdquo;, which is measured by the user\u0026rsquo;s IP address at the time of login.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe probability that a legitimate user is denied access is $1-0.99^n$ , where $n$ is the number of factors required. Similarly, the probability that a hacker is granted access is $0.01^n$ . This model becomes more complicated if different factors have different false positive/negative rates or are combined in different ways (for example, one scheme could require either a password or a fingerprint).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis explicitly assumes that any given login attempt has an equal chance of being malicious or legitimate, and it implicitly assumes that the \u0026ldquo;hacked\u0026rdquo; and \u0026ldquo;locked out\u0026rdquo; events are equally bad. Neither of these assumptions are true for most systems.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nUsing the fourth category of authentication factors \u0026ldquo;location\u0026rdquo;, one could implement a \u0026ldquo;2/4\u0026rdquo; or \u0026ldquo;3/4\u0026rdquo; strategy.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://hugo.roman.computer/mfa/","summary":"multi-factor authentication When you sign into an online service, you\u0026rsquo;re required to provide a username to identify who you are and a password to prove that you are who you say you are. Anyone can claim that they\u0026rsquo;re romanhn on GitHub, but only I know my GitHub password. But if a hacker breaches GitHub\u0026rsquo;s servers and publishes a list of everyone\u0026rsquo;s password,1 knowing my password is no longer proof of anything.","title":"🔐 the 2/3 rule for multi-factor authentication"},{"content":"note Since i originally wrote this post, i stumbled across the subreddit r/OSINT (open-source intelligence gathering). If you browse the top posts of all time, you can find megalists of hundreds of tools to help you find information on the internet. There\u0026rsquo;s also an \u0026ldquo;awesome\u0026rdquo; list for OSINT tools and Michael Bazzel\u0026rsquo;s OSINT Techniques: Resources for Uncovering Online Information.\nNeedless to say, this post is a bit useless in comparison, at least until i go through these comprehensive lists and filter for the most useful resources.\npresentation introduction Isn\u0026rsquo;t the internet such a magically useful tool? Thirty years ago, if you wanted to know how many plays Shakespeare wrote, you would have to physically walk to your local library and find a relevant book. Now, you can find the answer in less than ten seconds, at any time, wherever you are.\nHowever, the internet is not a truthful, superintelligent oracle. Rather, it\u0026rsquo;s a dangerous jungle of knowledge you must learn to navigate if you wish to find the truth. Good information is censored, hidden behind paywalls or within piles of spam, and difficult to differentiate from untrustworthy information. This post won\u0026rsquo;t be a complete guide on how to navigate the world wide web of knowledge, but it will give you some tools I\u0026rsquo;ve discovered over the years that you can throw in your digital rucksack to aid your journey.\nsearch engines The great internet sage Gwern Branwen wrote an advanced guide on finding ref­er­ences, pa­pers, and books on­line. The search engines Brave Search and Kagi have the features \u0026ldquo;Goggles\u0026rdquo; and \u0026ldquo;Lenses\u0026rdquo; respectively, which are presets that filter or re-rank entire categories of websites in your results. Blog Surf is a search engine for posts from manually approved personal blogs and newsletters. SearXNG is a highly customizable internet metasearch engine. Perplexity uses natural language processing to answer your query with a paragraph (with sources) and allows you to ask followup questions. Metaphor allows you to find websites by writing creative and long-form prompts, also using NLP. Elicit is a research assistant that helps you find relevant research papers, also using NLP. bypassing restrictions Sometimes you know exactly where to find a piece of information, but it\u0026rsquo;s locked behind a paywall or deleted from the internet.\nInternet Archive is a non-profit library of free books, movies, websites, et cetera. It\u0026rsquo;s famous for the Wayback Machine, which displays past archived snapshots of a given URL. Bypass Paywalls is a browser extension to help bypass paywalls on selected sites. The subreddit r/piracy has a wiki with loads of resources on obtaining copyrighted material for free. Anna\u0026rsquo;s Archive is a shadow library metasearch engine that aggregates results from websites that host copyrighted books, academic papers, magazines, et cetera. trustworthy sources It is particularly frustrating to find trustworthy knowledge about certain topics because of misaligned incentives: researching which product to buy or which supplements actually work is hard because everyone\u0026rsquo;s trying to sell you something.\nConsumer Reports independently tests consumer products and gives in-depth recommendations. It does not rely on affiliate commissions. Examine is a database of research about nutrition and supplements that has no industry ties, sponsorships, or ads. ","permalink":"https://hugo.roman.computer/information/","summary":"note Since i originally wrote this post, i stumbled across the subreddit r/OSINT (open-source intelligence gathering). If you browse the top posts of all time, you can find megalists of hundreds of tools to help you find information on the internet. There\u0026rsquo;s also an \u0026ldquo;awesome\u0026rdquo; list for OSINT tools and Michael Bazzel\u0026rsquo;s OSINT Techniques: Resources for Uncovering Online Information.\nNeedless to say, this post is a bit useless in comparison, at least until i go through these comprehensive lists and filter for the most useful resources.","title":"🔍 tools for finding information on the internet"},{"content":"","permalink":"https://hugo.roman.computer/list/","summary":"posts","title":"posts"}]